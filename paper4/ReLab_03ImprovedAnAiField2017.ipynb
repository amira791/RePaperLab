{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb41cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97edb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26765db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "train_dir = \"D:\\PFE\\D2\\wdd2017\\Training\"\n",
    "val_dir = \"D:\\PFE\\D2\\wdd2017\\Validation\"\n",
    "test_dir = \"D:\\PFE\\D2\\wdd2017\\Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b95811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for balanced datasets\n",
    "balanced_train_dir = \"balanced_train_data\"\n",
    "balanced_val_dir = \"balanced_val_data\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(balanced_train_dir, exist_ok=True)\n",
    "os.makedirs(balanced_val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73254234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution function\n",
    "def analyze_class_distribution(directory):\n",
    "    \"\"\"\n",
    "    Counts the number of images in each class for a given directory.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for class_label in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_counts[class_label] = len(os.listdir(class_dir))\n",
    "    return Counter(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13607dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Class Counts: Counter({'Healthy': 1104, 'Yellow_Rust': 900, 'Brown_Rust': 890, 'Loose_Smut': 700, 'Septoria': 280})\n",
      "Original Validation Class Counts: Counter({'Healthy': 312, 'Yellow_Rust': 300, 'Brown_Rust': 200, 'Loose_Smut': 140, 'Septoria': 35})\n",
      "Target number of images per class: 1104\n"
     ]
    }
   ],
   "source": [
    "# Analyze datasets\n",
    "train_class_counts = analyze_class_distribution(train_dir)\n",
    "val_class_counts = analyze_class_distribution(val_dir)\n",
    "\n",
    "print(\"Original Training Class Counts:\", train_class_counts)\n",
    "print(\"Original Validation Class Counts:\", val_class_counts)\n",
    "\n",
    "# Find the maximum class count (target balance)\n",
    "max_count = max(train_class_counts.values())\n",
    "print(f\"Target number of images per class: {max_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a05849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target number of images per class: 1104\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum class count (target balance)\n",
    "max_count = max(train_class_counts.values())\n",
    "print(f\"Target number of images per class: {max_count}\")\n",
    "\n",
    "# Augmentation generator for balancing underrepresented classes\n",
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdca2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 214 images for class Brown_Rust...\n",
      "Augmenting 404 images for class Loose_Smut...\n",
      "Augmenting 824 images for class Septoria...\n",
      "Augmenting 204 images for class Yellow_Rust...\n",
      "Dataset balanced successfully in: balanced_train_data\n",
      "Augmenting 904 images for class Brown_Rust...\n",
      "Augmenting 792 images for class Healthy...\n",
      "Augmenting 964 images for class Loose_Smut...\n",
      "Augmenting 1069 images for class Septoria...\n",
      "Augmenting 804 images for class Yellow_Rust...\n",
      "Dataset balanced successfully in: balanced_val_data\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Augmentation generator\n",
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def balance_dataset(source_dir, target_dir, class_counts, max_count, augment=False):\n",
    "    \"\"\"\n",
    "    Balances a dataset by copying existing images and optionally augmenting underrepresented classes.\n",
    "    \"\"\"\n",
    "    for class_label, count in class_counts.items():\n",
    "        src_class_dir = os.path.join(source_dir, class_label)\n",
    "        dst_class_dir = os.path.join(target_dir, class_label)\n",
    "        os.makedirs(dst_class_dir, exist_ok=True)\n",
    "\n",
    "        # Copy existing images\n",
    "        for file in os.listdir(src_class_dir):\n",
    "            shutil.copy(os.path.join(src_class_dir, file), dst_class_dir)\n",
    "\n",
    "        # Augment images if needed\n",
    "        if augment and count < max_count:\n",
    "            augmentation_target = max_count - count\n",
    "            print(f\"Augmenting {augmentation_target} images for class {class_label}...\")\n",
    "\n",
    "            # Augment images\n",
    "            augmented_count = 0\n",
    "            # Create a flow for augmenting individual images\n",
    "            for img_file in os.listdir(src_class_dir):\n",
    "                if augmented_count >= augmentation_target:\n",
    "                    break\n",
    "\n",
    "                img_path = os.path.join(src_class_dir, img_file)\n",
    "                # Open the image to augment\n",
    "                img = load_img(img_path)\n",
    "                x = img_to_array(img)  # Convert image to array\n",
    "                x = x.reshape((1,) + x.shape)  # Reshape for flow\n",
    "\n",
    "                # Create a generator that will save augmented images\n",
    "                i = 0\n",
    "                for batch in augmentation_datagen.flow(x, batch_size=1, save_to_dir=dst_class_dir,\n",
    "                                                       save_prefix=\"aug\", save_format=\"jpeg\"):\n",
    "                    i += 1\n",
    "                    if i >= 1:  # Only one augmentation per image\n",
    "                        break\n",
    "                augmented_count += 1\n",
    "\n",
    "    print(f\"Dataset balanced successfully in: {target_dir}\")\n",
    "\n",
    "# Balance training and validation datasets\n",
    "balance_dataset(train_dir, balanced_train_dir, train_class_counts, max_count, augment=True)\n",
    "balance_dataset(val_dir, balanced_val_dir, val_class_counts, max_count, augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24063838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in balanced_train_data: Counter({'Healthy': 1104, 'Brown_Rust': 1103, 'Yellow_Rust': 1101, 'Loose_Smut': 1099, 'Septoria': 557})\n",
      "Class counts in balanced_val_data: Counter({'Healthy': 618, 'Yellow_Rust': 594, 'Brown_Rust': 399, 'Loose_Smut': 279, 'Septoria': 70})\n"
     ]
    }
   ],
   "source": [
    "# Check balanced datasets\n",
    "def check_balanced_distribution(directory):\n",
    "    \"\"\"\n",
    "    Checks and prints the class distribution in the balanced dataset.\n",
    "    \"\"\"\n",
    "    balanced_counts = analyze_class_distribution(directory)\n",
    "    print(f\"Class counts in {directory}: {balanced_counts}\")\n",
    "    return balanced_counts\n",
    "\n",
    "# Check distributions\n",
    "train_balanced_counts = check_balanced_distribution(balanced_train_dir)\n",
    "val_balanced_counts = check_balanced_distribution(balanced_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f547f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in balanced_train_data: Counter({'Healthy': 1104, 'Brown_Rust': 1103, 'Yellow_Rust': 1101, 'Loose_Smut': 1099, 'Septoria': 557})\n",
      "Class counts in balanced_val_data: Counter({'Healthy': 618, 'Yellow_Rust': 594, 'Brown_Rust': 399, 'Loose_Smut': 279, 'Septoria': 70})\n",
      "Found 4931 images belonging to 5 classes.\n",
      "Found 1960 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Check distributions\n",
    "train_balanced_counts = check_balanced_distribution(balanced_train_dir)\n",
    "val_balanced_counts = check_balanced_distribution(balanced_val_dir)\n",
    "\n",
    "# Set up the ImageDataGenerators for training and validation sets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Load training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    balanced_train_dir,\n",
    "    target_size=(224, 224),  # Resize images to match model input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Assuming a classification task\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    balanced_val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d7678c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41288632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 5s/step - accuracy: 0.4766 - loss: 1.2934 - val_accuracy: 0.8007 - val_loss: 0.6369\n",
      "Epoch 2/30\n",
      "\u001b[1m  1/154\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:44\u001b[0m 4s/step - accuracy: 0.6562 - loss: 0.9145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 341ms/step - accuracy: 0.6562 - loss: 0.9145 - val_accuracy: 0.7587 - val_loss: 0.7694\n",
      "Epoch 3/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.7624 - loss: 0.6658 - val_accuracy: 0.7941 - val_loss: 0.7567\n",
      "Epoch 4/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 309ms/step - accuracy: 0.9375 - loss: 0.3487 - val_accuracy: 0.7418 - val_loss: 0.9019\n",
      "Epoch 5/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 4s/step - accuracy: 0.8142 - loss: 0.5343 - val_accuracy: 0.8509 - val_loss: 0.6499\n",
      "Epoch 6/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 315ms/step - accuracy: 0.9375 - loss: 0.2866 - val_accuracy: 0.8571 - val_loss: 0.6658\n",
      "Epoch 7/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 3s/step - accuracy: 0.8321 - loss: 0.4726 - val_accuracy: 0.7818 - val_loss: 1.1118\n",
      "Epoch 8/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 268ms/step - accuracy: 0.8125 - loss: 0.3699 - val_accuracy: 0.7715 - val_loss: 1.1208\n",
      "Epoch 9/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 3s/step - accuracy: 0.8658 - loss: 0.3964 - val_accuracy: 0.8274 - val_loss: 1.3277\n",
      "Epoch 10/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 270ms/step - accuracy: 0.9062 - loss: 0.3893 - val_accuracy: 0.8258 - val_loss: 1.3315\n",
      "Epoch 11/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 3s/step - accuracy: 0.8899 - loss: 0.3542 - val_accuracy: 0.8576 - val_loss: 0.9559\n",
      "Epoch 12/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 302ms/step - accuracy: 0.9688 - loss: 0.1358 - val_accuracy: 0.8601 - val_loss: 0.9190\n",
      "Epoch 13/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 3s/step - accuracy: 0.8875 - loss: 0.3126 - val_accuracy: 0.8489 - val_loss: 0.9873\n",
      "Epoch 14/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 308ms/step - accuracy: 0.8750 - loss: 0.3036 - val_accuracy: 0.8601 - val_loss: 0.8988\n",
      "Epoch 15/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 4s/step - accuracy: 0.8909 - loss: 0.3105 - val_accuracy: 0.8294 - val_loss: 0.9890\n",
      "Epoch 16/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 342ms/step - accuracy: 0.8750 - loss: 0.3842 - val_accuracy: 0.8151 - val_loss: 1.0763\n",
      "Epoch 17/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 3s/step - accuracy: 0.8871 - loss: 0.3205 - val_accuracy: 0.8576 - val_loss: 1.0944\n",
      "Epoch 18/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 314ms/step - accuracy: 0.7500 - loss: 0.6006 - val_accuracy: 0.8443 - val_loss: 1.2320\n",
      "Epoch 19/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 3s/step - accuracy: 0.8895 - loss: 0.2914 - val_accuracy: 0.8560 - val_loss: 0.9781\n",
      "Epoch 20/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 299ms/step - accuracy: 0.9062 - loss: 0.3958 - val_accuracy: 0.8586 - val_loss: 1.0731\n",
      "Epoch 21/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 3s/step - accuracy: 0.9131 - loss: 0.2556 - val_accuracy: 0.8663 - val_loss: 1.0509\n",
      "Epoch 22/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 275ms/step - accuracy: 0.9688 - loss: 0.1324 - val_accuracy: 0.8627 - val_loss: 0.9984\n",
      "Epoch 23/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 3s/step - accuracy: 0.9143 - loss: 0.2568 - val_accuracy: 0.8663 - val_loss: 1.0703\n",
      "Epoch 24/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 443ms/step - accuracy: 0.9688 - loss: 0.1364 - val_accuracy: 0.8699 - val_loss: 1.0605\n",
      "Epoch 25/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 4s/step - accuracy: 0.9215 - loss: 0.2271 - val_accuracy: 0.8458 - val_loss: 1.4400\n",
      "Epoch 26/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 278ms/step - accuracy: 0.8438 - loss: 0.4877 - val_accuracy: 0.8566 - val_loss: 1.3398\n",
      "Epoch 27/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 3s/step - accuracy: 0.9189 - loss: 0.2315 - val_accuracy: 0.8438 - val_loss: 1.3399\n",
      "Epoch 28/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 282ms/step - accuracy: 0.9062 - loss: 0.3713 - val_accuracy: 0.8422 - val_loss: 1.3433\n",
      "Epoch 29/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 3s/step - accuracy: 0.9313 - loss: 0.2085 - val_accuracy: 0.8683 - val_loss: 0.9840\n",
      "Epoch 30/30\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 296ms/step - accuracy: 0.8750 - loss: 0.3753 - val_accuracy: 0.8663 - val_loss: 0.9706\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 845ms/step - accuracy: 0.8631 - loss: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9671390056610107\n",
      "Validation Accuracy: 0.8668367266654968\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,  # Adjust the number of epochs based on your requirements\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('wheat_disease_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee9ef0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.8946 - loss: 0.3500\n",
      "Test Loss: 0.6083817481994629\n",
      "Test Accuracy: 0.811965823173523\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b2e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 693 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),  # Resize images to match model input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important: Do not shuffle test data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79070b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.4500 - loss: 4.3689\n",
      "Test Loss: 6.886234760284424\n",
      "Test Accuracy: 0.48917749524116516\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b5dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"D:\\PFE\\Datasets\\Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38c46d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8897 - loss: 0.4025\n",
      "Test Loss: 0.6879528760910034\n",
      "Test Accuracy: 0.805084764957428\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4491922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 117 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),  # Resize images to match model input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important: Do not shuffle test data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daba11e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step\n",
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 4, does not match size of target_names, 5. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(true_classes, predicted_classes))\n",
      "File \u001b[1;32m~\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\PFETesting\\paper1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2690\u001b[0m             )\n\u001b[0;32m   2691\u001b[0m         )\n\u001b[0;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2697\u001b[0m         )\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 4, does not match size of target_names, 5. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Get predictions for the test set\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class indices\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "\n",
    "# Get the true class labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Compare predicted vs true labels\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=test_generator.class_indices.keys()))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_classes, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8b4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amiratest1",
   "language": "python",
   "name": "amiratest1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
