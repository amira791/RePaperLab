{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120f2d8a-7f50-4d1e-8b4c-11c1e4d270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c943682-5ebe-4dfe-aa19-4f2a54d450c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    images, labels = [], []\n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        for img_file in os.listdir(os.path.join(dataset_path, label_dir)):\n",
    "            img_path = os.path.join(dataset_path, label_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, img_size)\n",
    "            images.append(image)\n",
    "            labels.append(label_dir)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444571d4-87b0-4121-9c33-e248f08da397",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images_and_labels(\"./wheat_leaf\")\n",
    "images = images / 255.0  # Normalisation des images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e42ea1f-2e50-4f83-bb4f-25c1902c89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des étiquettes\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)  # Encodage des étiquettes en one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13caaef-b285-44e6-8d1f-0599bf35e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division en ensembles train, validation et test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773adc49-2727-45a9-8f19-317a16acd866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans le training set : Counter({2: 150, 1: 70, 0: 64})\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la distribution des classes dans le training set\n",
    "class_distribution = Counter(np.argmax(y_train, axis=1))\n",
    "print(\"Distribution des classes dans le training set :\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5268dec-0308-469d-a548-bd021a19a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de SMOTETomek pour équilibrer les classes\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)  # Aplatir les images\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X_train_flattened, np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2550e7-09e0-481b-8d35-9573c2523f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape des données augmentées\n",
    "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c029cd1-4bbb-48d0-af67-1d140bc5608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_augmented_train: (734, 224, 224, 3)\n",
      "Shape of y_augmented_train: (734, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convertir y_resampled en one-hot encoding\n",
    "y_resampled_one_hot = to_categorical(y_resampled, num_classes=labels.shape[1])\n",
    "\n",
    "# Fusionner les données d'origine et les données augmentées\n",
    "X_augmented_train = np.vstack((X_train, X_resampled))\n",
    "y_augmented_train = np.vstack((y_train, y_resampled_one_hot))\n",
    "\n",
    "print(\"Shape of X_augmented_train:\", X_augmented_train.shape)\n",
    "print(\"Shape of y_augmented_train:\", y_augmented_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c579207-c47b-4335-b04e-7d5819a75e43",
   "metadata": {},
   "source": [
    "### ______________________________________________________ Xception ______________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c397ae8e-ef9d-41ab-bce9-2770bfe417e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_augmented_train dtype: float64\n",
      "y_augmented_train dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "# Construction du modèle MobileNetV2\n",
    "Xception_model = Xception(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "Xception_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    Xception_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(labels.shape[1], activation='softmax')  # Nombre de classes dynamique\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Vérification des types de données\n",
    "print(\"X_augmented_train dtype:\", X_augmented_train.dtype)\n",
    "print(\"y_augmented_train dtype:\", y_augmented_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914480ee-4081-4509-8697-5f7e52e17adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.6739 - loss: 0.6462 - val_accuracy: 0.8689 - val_loss: 0.3130\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.9630 - loss: 0.1222 - val_accuracy: 0.9180 - val_loss: 0.2184\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.9899 - loss: 0.0577 - val_accuracy: 0.9180 - val_loss: 0.2297\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.9016 - val_loss: 0.2227\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.9970 - loss: 0.0273 - val_accuracy: 0.8852 - val_loss: 0.3265\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.9016 - val_loss: 0.2699\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9016 - val_loss: 0.3017\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9180 - val_loss: 0.2600\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9180 - val_loss: 0.2930\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9180 - val_loss: 0.2699\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9344 - val_loss: 0.2872\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9344 - val_loss: 0.2891\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9344 - val_loss: 0.2953\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9180 - val_loss: 0.3009\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9180 - val_loss: 0.3112\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9344 - val_loss: 0.2991\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9180 - val_loss: 0.3254\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9180 - val_loss: 0.3178\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.3051\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9344 - val_loss: 0.3096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f939703920>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle avec les données augmentées\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "968d4e7b-63c0-4a97-86a3-5e9b837cd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.9788 - loss: 0.1260\n",
      "Précision sur l'ensemble test : 0.98\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adcdaff7-c54d-4040-963d-09e5d9617572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cef8d3-ac74-4fe6-a3e9-e4226a9dafbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 13  0]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      1.00      0.97        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.98        62\n",
      "   macro avg       0.98      0.99      0.99        62\n",
      "weighted avg       0.98      0.98      0.98        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b0346-53b3-4068-8028-c660100a5dbc",
   "metadata": {},
   "source": [
    "### _____________________________________________________  MobileNetV2 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f1b7d9-0e6b-436f-89e8-5a8d44462946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_augmented_train dtype: float64\n",
      "y_augmented_train dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "# Construction du modèle MobileNetV2\n",
    "MobileNetV2_model = MobileNetV2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "MobileNetV2_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    MobileNetV2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(labels.shape[1], activation='softmax')  # Nombre de classes dynamique\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Vérification des types de données\n",
    "print(\"X_augmented_train dtype:\", X_augmented_train.dtype)\n",
    "print(\"y_augmented_train dtype:\", y_augmented_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e373f7-f806-47b5-a53b-1beeb5e2e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 614ms/step - accuracy: 0.6497 - loss: 0.8954 - val_accuracy: 0.8525 - val_loss: 0.3277\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 503ms/step - accuracy: 0.9663 - loss: 0.1005 - val_accuracy: 0.9344 - val_loss: 0.1883\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 507ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.9508 - val_loss: 0.1593\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.9508 - val_loss: 0.1446\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 572ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9508 - val_loss: 0.1384\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9508 - val_loss: 0.1457\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9508 - val_loss: 0.1501\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9508 - val_loss: 0.1531\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9508 - val_loss: 0.1452\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9508 - val_loss: 0.1506\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9508 - val_loss: 0.1461\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9508 - val_loss: 0.1509\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 576ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9508 - val_loss: 0.1472\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 511ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9508 - val_loss: 0.1579\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9508 - val_loss: 0.1495\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9508 - val_loss: 0.1546\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9508 - val_loss: 0.1558\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 509ms/step - accuracy: 1.0000 - loss: 9.7243e-04 - val_accuracy: 0.9508 - val_loss: 0.1585\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 7.9982e-04 - val_accuracy: 0.9508 - val_loss: 0.1579\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 1.0000 - loss: 7.2327e-04 - val_accuracy: 0.9508 - val_loss: 0.1594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f98d6ee180>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle avec les données augmentées\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0aed486-6f4c-4814-9f9a-356199955d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.9362 - loss: 0.1194\n",
      "Précision sur l'ensemble test : 0.94\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606bdc45-077f-4bc6-89aa-b899645ce1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f160565e-28d1-4f69-96ab-00cf82b49490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.89      0.91        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.91      0.97      0.94        31\n",
      "\n",
      "    accuracy                           0.94        62\n",
      "   macro avg       0.95      0.93      0.94        62\n",
      "weighted avg       0.94      0.94      0.94        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e4863-3680-4dd5-aa90-05ea51a6156c",
   "metadata": {},
   "source": [
    "### _______________________________________________ ResNet50V2 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e95b4fc-8192-46cc-b45a-8be251fa99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_augmented_train dtype: float64\n",
      "y_augmented_train dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "# Construction du modèle MobileNetV2\n",
    "ResNet50V2_model = ResNet50V2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "ResNet50V2_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    ResNet50V2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(labels.shape[1], activation='softmax')  # Nombre de classes dynamique\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Vérification des types de données\n",
    "print(\"X_augmented_train dtype:\", X_augmented_train.dtype)\n",
    "print(\"y_augmented_train dtype:\", y_augmented_train.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf67178f-da48-4ac6-abf0-8fa6d890ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.6417 - loss: 0.8710 - val_accuracy: 0.8689 - val_loss: 0.2537\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9887 - loss: 0.0704 - val_accuracy: 0.8689 - val_loss: 0.2182\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0304 - val_accuracy: 0.8852 - val_loss: 0.1734\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.8852 - val_loss: 0.1987\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.8852 - val_loss: 0.2071\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8852 - val_loss: 0.2058\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8852 - val_loss: 0.2047\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8852 - val_loss: 0.2056\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8852 - val_loss: 0.2163\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8852 - val_loss: 0.2221\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8852 - val_loss: 0.2243\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8852 - val_loss: 0.2318\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8852 - val_loss: 0.2328\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.2352\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.0098e-04 - val_accuracy: 0.8852 - val_loss: 0.2384\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.6836e-04 - val_accuracy: 0.8852 - val_loss: 0.2416\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.2518e-04 - val_accuracy: 0.8852 - val_loss: 0.2407\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.2558e-04 - val_accuracy: 0.8852 - val_loss: 0.2484\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.6907e-04 - val_accuracy: 0.8852 - val_loss: 0.2409\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.5060e-04 - val_accuracy: 0.8852 - val_loss: 0.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fa0f7e1a00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle avec les données augmentées\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75c12935-f75a-4fd5-b3d5-80538f4050db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9362 - loss: 0.1118\n",
      "Précision sur l'ensemble test : 0.94\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e52736d-ae6b-4471-802d-becdbf7f4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F97EE7B100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F97EE7B100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14da6e17-5518-4c12-a81b-02c9caf7d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.89      0.91        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.91      0.97      0.94        31\n",
      "\n",
      "    accuracy                           0.94        62\n",
      "   macro avg       0.95      0.93      0.94        62\n",
      "weighted avg       0.94      0.94      0.94        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1565a0-240c-4287-aaa6-5f4bffb525ae",
   "metadata": {},
   "source": [
    "### ____________________________________________________ DenseNet121 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "428f5b2c-cbe1-4bf1-8fdf-d6c3a19bd947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_augmented_train dtype: float64\n",
      "y_augmented_train dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet121_model = DenseNet121(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet121_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet121_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(labels.shape[1], activation='softmax')  # Nombre de classes dynamique\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Vérification des types de données\n",
    "print(\"X_augmented_train dtype:\", X_augmented_train.dtype)\n",
    "print(\"y_augmented_train dtype:\", y_augmented_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "334b96ef-f447-4cfa-be61-9c36715f4163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.6268 - loss: 0.7967 - val_accuracy: 0.8197 - val_loss: 0.3832\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9244 - loss: 0.2099 - val_accuracy: 0.9180 - val_loss: 0.1945\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9873 - loss: 0.0776 - val_accuracy: 0.9672 - val_loss: 0.1365\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9967 - loss: 0.0478 - val_accuracy: 0.9344 - val_loss: 0.1391\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 0.9672 - val_loss: 0.1026\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.9672 - val_loss: 0.0958\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.9672 - val_loss: 0.0843\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9672 - val_loss: 0.0870\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9672 - val_loss: 0.0854\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9672 - val_loss: 0.0823\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9672 - val_loss: 0.0762\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9672 - val_loss: 0.0755\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9672 - val_loss: 0.0728\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9672 - val_loss: 0.0731\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9836 - val_loss: 0.0677\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9836 - val_loss: 0.0677\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9836 - val_loss: 0.0672\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9672 - val_loss: 0.0656\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9836 - val_loss: 0.0637\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9836 - val_loss: 0.0645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fa1d539a00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle avec les données augmentées\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e799fe7-f98a-429b-8c10-71086a8cca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 0.0630\n",
      "Précision sur l'ensemble test : 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e89a2e8-d61e-4cd2-be20-810e9e7d2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeb3260a-1eef-46ad-8d6d-75e90f9960b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      1.00      1.00        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           0.98        62\n",
      "   macro avg       0.99      0.97      0.98        62\n",
      "weighted avg       0.98      0.98      0.98        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2479a69-8b68-43f9-b1f5-48e9bcdcd3fe",
   "metadata": {},
   "source": [
    "### _____________________________________________________ DenseNet169 _____________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3998afae-dd23-4942-9a3b-5f12302163c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_augmented_train dtype: float64\n",
      "y_augmented_train dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet169_model = DenseNet169(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet169_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet169_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(labels.shape[1], activation='softmax')  # Nombre de classes dynamique\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Vérification des types de données\n",
    "print(\"X_augmented_train dtype:\", X_augmented_train.dtype)\n",
    "print(\"y_augmented_train dtype:\", y_augmented_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd55e1b8-3112-4542-8dca-1860d2ccac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4s/step - accuracy: 0.7397 - loss: 0.6108 - val_accuracy: 0.8361 - val_loss: 0.3279\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.9734 - loss: 0.1089 - val_accuracy: 0.9344 - val_loss: 0.2357\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0414 - val_accuracy: 0.9344 - val_loss: 0.1781\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 0.9508 - val_loss: 0.1741\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9508 - val_loss: 0.1990\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9344 - val_loss: 0.2029\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9344 - val_loss: 0.2090\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9508 - val_loss: 0.1777\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9508 - val_loss: 0.1876\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9508 - val_loss: 0.1809\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9508 - val_loss: 0.1801\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9508 - val_loss: 0.1763\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9508 - val_loss: 0.2040\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9180 - val_loss: 0.2166\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9344 - val_loss: 0.2075\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9508 - val_loss: 0.1864\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9508 - val_loss: 0.1825\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9344 - val_loss: 0.2066\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 9.9702e-04 - val_accuracy: 0.9344 - val_loss: 0.2062\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.8673e-04 - val_accuracy: 0.9508 - val_loss: 0.2007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fa6970e840>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle avec les données augmentées\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a23035d-b875-4343-98a8-275cab0fd1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.1083\n",
      "Précision sur l'ensemble test : 0.97\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60df9d72-2fd9-40cc-8d67-82fd0c321573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "becfd0c4-4288-406c-a9bd-65861a6d63dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 13  0]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      0.89      0.94        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       0.94      1.00      0.97        31\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.98      0.96      0.97        62\n",
      "weighted avg       0.97      0.97      0.97        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Rapport de classification\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
