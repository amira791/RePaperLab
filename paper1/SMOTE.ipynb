{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c05c9e-5a3f-461c-94bc-5c8dc676170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60506909-dfa0-480c-bf1a-37dbf9c67246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    images, labels = [], []\n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        for img_file in os.listdir(os.path.join(dataset_path, label_dir)):\n",
    "            img_path = os.path.join(dataset_path, label_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, img_size)\n",
    "            images.append(image)\n",
    "            labels.append(label_dir)\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0894ca24-2354-4cf9-b6e9-13bf93511ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images_and_labels(\"./wheat_leaf\")\n",
    "images = images / 255.0  # Normalisation des images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733b0816-8f68-4aaa-abf6-871fb81cea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des étiquettes\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2201c3e-4ae1-41cc-b9a4-4caa3d8f58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division en ensembles train, validation et test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d251b615-9a0d-4d19-88d0-b625d9cdc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans le training set : Counter({2: 150, 1: 70, 0: 64})\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la distribution des classes dans le training set\n",
    "class_distribution = Counter(np.argmax(y_train, axis=1))\n",
    "print(\"Distribution des classes dans le training set :\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501a9f19-f1a6-4cbf-b8be-cfebad234a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de SMOTE pour équilibrer les classes\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)  # Aplatir les données pour SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_augmented, y_augmented = smote.fit_resample(X_train_flattened, np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54df04fb-4496-4464-85e4-9ad147e03615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape des données augmentées\n",
    "X_augmented = X_augmented.reshape(-1, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216995d3-1543-4f45-a8e5-264f5dc8d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_augmented_train: (734, 224, 224, 3)\n",
      "Shape of y_augmented_train: (734, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convertir y_augmented en one-hot encoding\n",
    "y_augmented_one_hot = to_categorical(y_augmented, num_classes=3)\n",
    "\n",
    "# Fusionner les données (X) et les étiquettes (y)\n",
    "X_augmented_train = np.vstack((X_train, X_augmented))\n",
    "y_augmented_train = np.vstack((y_train, y_augmented_one_hot))\n",
    "\n",
    "print(\"Shape of X_augmented_train:\", X_augmented_train.shape)\n",
    "print(\"Shape of y_augmented_train:\", y_augmented_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97faad-e0c4-446d-839a-c377e8ce5698",
   "metadata": {},
   "source": [
    "### _________________________________________________ Xception _________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294f9b77-8b89-4a2b-b5c8-5a2aa9b5e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "Xception_model = Xception(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "Xception_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f01c641-def5-44d6-93c6-ab5a40bcbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Xception_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06787ef2-dd64-4c7a-9aac-b9c537a36ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f16361-36f9-46f9-b2c6-48528d4fdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 6s/step - accuracy: 0.6106 - loss: 0.7476 - val_accuracy: 0.8361 - val_loss: 0.3785\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 6s/step - accuracy: 0.9295 - loss: 0.2124 - val_accuracy: 0.8525 - val_loss: 0.3482\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 6s/step - accuracy: 0.9743 - loss: 0.0937 - val_accuracy: 0.9180 - val_loss: 0.2373\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 6s/step - accuracy: 0.9848 - loss: 0.0700 - val_accuracy: 0.8852 - val_loss: 0.2439\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.9991 - loss: 0.0339 - val_accuracy: 0.8361 - val_loss: 0.3619\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.9016 - val_loss: 0.2457\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8852 - val_loss: 0.3165\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9016 - val_loss: 0.2944\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.8852 - val_loss: 0.2771\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9016 - val_loss: 0.2762\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9180 - val_loss: 0.2801\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9016 - val_loss: 0.2897\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9016 - val_loss: 0.3380\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9180 - val_loss: 0.3121\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9180 - val_loss: 0.3175\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9180 - val_loss: 0.3042\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9180 - val_loss: 0.2894\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9180 - val_loss: 0.2985\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9180 - val_loss: 0.3078\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9016 - val_loss: 0.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188280c3e00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1287e0cf-60eb-43a8-bb36-a4e9ef8cec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.9788 - loss: 0.1208\n",
      "Précision sur l'ensemble test : 0.98\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1960e9ad-6bcb-4802-9de9-23f2c918335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4dc3fa-ee74-4c00-899c-5d6fd9609844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 13  0]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      1.00      0.97        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.98        62\n",
      "   macro avg       0.98      0.99      0.99        62\n",
      "weighted avg       0.98      0.98      0.98        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f578e-8f3f-4503-9492-1a2047373a72",
   "metadata": {},
   "source": [
    "### ____________________________ MobileNetV2 ___________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77f4ae3-6eed-4ba4-a840-78253b7d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "MobileNetV2_model = MobileNetV2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "MobileNetV2_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7472e4bc-7836-4a4b-985b-08ab7b2d033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    MobileNetV2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d92f305f-0e6d-4f30-aef9-480baeb519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79e4b17-660d-40b6-a904-17d2ea611528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 930ms/step - accuracy: 0.6978 - loss: 0.5854 - val_accuracy: 0.8852 - val_loss: 0.2925\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 651ms/step - accuracy: 0.9858 - loss: 0.0621 - val_accuracy: 0.8689 - val_loss: 0.2711\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 571ms/step - accuracy: 0.9843 - loss: 0.0429 - val_accuracy: 0.9508 - val_loss: 0.1715\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 542ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9344 - val_loss: 0.1765\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9180 - val_loss: 0.1810\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 653ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9180 - val_loss: 0.1934\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9344 - val_loss: 0.1809\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9180 - val_loss: 0.1956\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9016 - val_loss: 0.2106\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 612ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9344 - val_loss: 0.1958\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 577ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9180 - val_loss: 0.2024\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9344 - val_loss: 0.1988\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 512ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9344 - val_loss: 0.1957\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 552ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1941\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 568ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9344 - val_loss: 0.1958\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9344 - val_loss: 0.1962\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9344 - val_loss: 0.2095\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 8.1141e-04 - val_accuracy: 0.9344 - val_loss: 0.2028\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 521ms/step - accuracy: 1.0000 - loss: 8.9021e-04 - val_accuracy: 0.9344 - val_loss: 0.2031\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 6.9993e-04 - val_accuracy: 0.9344 - val_loss: 0.2067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18877f45f10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6678ac69-a4fe-4046-9823-6d59b787f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.9150 - loss: 0.1649\n",
      "Précision sur l'ensemble test : 0.92\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d038f752-a0ad-44ea-841f-b7ed44696b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07147d48-9fb6-48f8-a984-c8eb410089ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[15  0  3]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.83      0.88        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.88      0.97      0.92        31\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.94      0.91      0.92        62\n",
      "weighted avg       0.92      0.92      0.92        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36ddde-3133-472f-a991-b981ab35d200",
   "metadata": {},
   "source": [
    "### ______________________________________________ DenceNet121 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c729e55-e2f3-4672-bae9-add740d2da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet121_model = DenseNet121(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet121_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet121_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8869314-233b-4bea-8b5a-4e7433378c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - accuracy: 0.6852 - loss: 0.6990 - val_accuracy: 0.9016 - val_loss: 0.3084\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.9359 - loss: 0.1688 - val_accuracy: 0.9672 - val_loss: 0.1935\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9856 - loss: 0.0815 - val_accuracy: 0.9180 - val_loss: 0.1801\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0394 - val_accuracy: 0.9836 - val_loss: 0.1290\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.9836 - val_loss: 0.1187\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.9836 - val_loss: 0.1188\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9836 - val_loss: 0.1110\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9836 - val_loss: 0.1067\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9836 - val_loss: 0.1046\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9836 - val_loss: 0.1019\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9836 - val_loss: 0.0990\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9836 - val_loss: 0.1015\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9836 - val_loss: 0.0953\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9836 - val_loss: 0.0940\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9836 - val_loss: 0.0924\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9836 - val_loss: 0.0918\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9836 - val_loss: 0.0905\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1771s\u001b[0m 80s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9836 - val_loss: 0.0946\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9836 - val_loss: 0.0894\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9836 - val_loss: 0.0923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188974b4a70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0ccacd-5153-427b-a008-b9478d751142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9785 - loss: 0.0427\n",
      "Précision sur l'ensemble test : 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a54955-38b1-45cb-867e-0ffc2acea6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001890A5C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 16s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001890A5C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "253636f1-848a-4fb4-b6da-fc6ec01bced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      1.00      1.00        18\n",
      "    septoria       1.00      0.85      0.92        13\n",
      " stripe_rust       0.94      1.00      0.97        31\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.98      0.95      0.96        62\n",
      "weighted avg       0.97      0.97      0.97        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe90c0-9d55-4f8f-97f6-adc01db85389",
   "metadata": {},
   "source": [
    "### ________________________________________ DenseNet169 ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baef7a63-9540-4b39-83e8-77b7a9057ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet169_model = DenseNet169(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet169_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet169_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fc9f2d0-116a-4378-8699-e55f1f7b28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 5s/step - accuracy: 0.6506 - loss: 0.7964 - val_accuracy: 0.8197 - val_loss: 0.3906\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.9438 - loss: 0.1499 - val_accuracy: 0.9180 - val_loss: 0.2425\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.9848 - loss: 0.0623 - val_accuracy: 0.9180 - val_loss: 0.2384\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.9344 - val_loss: 0.1650\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.9180 - val_loss: 0.2333\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9344 - val_loss: 0.2150\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9344 - val_loss: 0.1831\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9344 - val_loss: 0.1687\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9344 - val_loss: 0.1835\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9344 - val_loss: 0.2067\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9344 - val_loss: 0.2086\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9344 - val_loss: 0.1961\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9344 - val_loss: 0.1948\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9344 - val_loss: 0.1810\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9344 - val_loss: 0.2073\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9344 - val_loss: 0.1971\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9344 - val_loss: 0.1919\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9344 - val_loss: 0.1795\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1872\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188974f4800>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c10ac2a-c892-440d-b246-7ee5ce93c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.1091\n",
      "Précision sur l'ensemble test : 0.97\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a61d315d-8200-4efd-b2d1-751f7ae830eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 22s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d66f127b-18d7-4be6-965d-8f5042a07f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 13  0]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      0.89      0.94        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       0.94      1.00      0.97        31\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.98      0.96      0.97        62\n",
      "weighted avg       0.97      0.97      0.97        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56ce50-1af4-4c9d-8c80-4fb6bc771195",
   "metadata": {},
   "source": [
    "### ____________________________________________ ResNet50V2 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9da1f1e-3e44-45f4-92e9-b7b6f0f4bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "# Construction du modèle MobileNetV2\n",
    "ResNet50V2_model = ResNet50V2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "ResNet50V2_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    ResNet50V2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40150701-899c-440d-9fcc-3e2e6053cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.7191 - loss: 0.6685 - val_accuracy: 0.8361 - val_loss: 0.3646\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9814 - loss: 0.0634 - val_accuracy: 0.9016 - val_loss: 0.2464\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8689 - val_loss: 0.2832\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8852 - val_loss: 0.2701\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8689 - val_loss: 0.2872\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8852 - val_loss: 0.2797\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8852 - val_loss: 0.2820\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8852 - val_loss: 0.2764\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8852 - val_loss: 0.2997\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8852 - val_loss: 0.2832\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8852 - val_loss: 0.2925\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.2918\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.2955\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8852 - val_loss: 0.2923\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.1562e-04 - val_accuracy: 0.8852 - val_loss: 0.2987\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.9567e-04 - val_accuracy: 0.8852 - val_loss: 0.3020\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.6005e-04 - val_accuracy: 0.8852 - val_loss: 0.3041\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.4164e-04 - val_accuracy: 0.8852 - val_loss: 0.3065\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 5.2828e-04 - val_accuracy: 0.8852 - val_loss: 0.3086\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.8260e-04 - val_accuracy: 0.8852 - val_loss: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1896d7d5610>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f98aef-d55f-4bf1-962a-24a67478df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9362 - loss: 0.0972\n",
      "Précision sur l'ensemble test : 0.94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "412b1c96-513f-408b-a06c-7ba4828ab85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f05093f5-6b86-4d1f-89b1-4187b95b8039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.89      0.91        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.91      0.97      0.94        31\n",
      "\n",
      "    accuracy                           0.94        62\n",
      "   macro avg       0.95      0.93      0.94        62\n",
      "weighted avg       0.94      0.94      0.94        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abbd0d-9828-4dd4-ae70-ace3197fb13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
