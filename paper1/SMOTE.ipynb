{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c05c9e-5a3f-461c-94bc-5c8dc676170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60506909-dfa0-480c-bf1a-37dbf9c67246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    images, labels = [], []\n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        for img_file in os.listdir(os.path.join(dataset_path, label_dir)):\n",
    "            img_path = os.path.join(dataset_path, label_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, img_size)\n",
    "            images.append(image)\n",
    "            labels.append(label_dir)\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0894ca24-2354-4cf9-b6e9-13bf93511ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_images_and_labels(\"./wheat_leaf\")\n",
    "images = images / 255.0  # Normalisation des images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733b0816-8f68-4aaa-abf6-871fb81cea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des étiquettes\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2201c3e-4ae1-41cc-b9a4-4caa3d8f58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division en ensembles train, validation et test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d251b615-9a0d-4d19-88d0-b625d9cdc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans le training set : Counter({2: 150, 1: 70, 0: 64})\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la distribution des classes dans le training set\n",
    "class_distribution = Counter(np.argmax(y_train, axis=1))\n",
    "print(\"Distribution des classes dans le training set :\", class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501a9f19-f1a6-4cbf-b8be-cfebad234a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de SMOTE pour équilibrer les classes\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)  # Aplatir les données pour SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_augmented, y_augmented = smote.fit_resample(X_train_flattened, np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54df04fb-4496-4464-85e4-9ad147e03615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape des données augmentées\n",
    "X_augmented = X_augmented.reshape(-1, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216995d3-1543-4f45-a8e5-264f5dc8d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_augmented_train: (734, 224, 224, 3)\n",
      "Shape of y_augmented_train: (734, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convertir y_augmented en one-hot encoding\n",
    "y_augmented_one_hot = to_categorical(y_augmented, num_classes=3)\n",
    "\n",
    "# Fusionner les données (X) et les étiquettes (y)\n",
    "X_augmented_train = np.vstack((X_train, X_augmented))\n",
    "y_augmented_train = np.vstack((y_train, y_augmented_one_hot))\n",
    "\n",
    "print(\"Shape of X_augmented_train:\", X_augmented_train.shape)\n",
    "print(\"Shape of y_augmented_train:\", y_augmented_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97faad-e0c4-446d-839a-c377e8ce5698",
   "metadata": {},
   "source": [
    "### _________________________________________________ Xception _________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294f9b77-8b89-4a2b-b5c8-5a2aa9b5e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "Xception_model = Xception(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "Xception_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f01c641-def5-44d6-93c6-ab5a40bcbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Xception_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06787ef2-dd64-4c7a-9aac-b9c537a36ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f16361-36f9-46f9-b2c6-48528d4fdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 6s/step - accuracy: 0.6106 - loss: 0.7476 - val_accuracy: 0.8361 - val_loss: 0.3785\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 6s/step - accuracy: 0.9295 - loss: 0.2124 - val_accuracy: 0.8525 - val_loss: 0.3482\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 6s/step - accuracy: 0.9743 - loss: 0.0937 - val_accuracy: 0.9180 - val_loss: 0.2373\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 6s/step - accuracy: 0.9848 - loss: 0.0700 - val_accuracy: 0.8852 - val_loss: 0.2439\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.9991 - loss: 0.0339 - val_accuracy: 0.8361 - val_loss: 0.3619\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.9016 - val_loss: 0.2457\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8852 - val_loss: 0.3165\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9016 - val_loss: 0.2944\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.8852 - val_loss: 0.2771\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9016 - val_loss: 0.2762\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9180 - val_loss: 0.2801\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9016 - val_loss: 0.2897\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9016 - val_loss: 0.3380\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9180 - val_loss: 0.3121\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9180 - val_loss: 0.3175\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9180 - val_loss: 0.3042\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9180 - val_loss: 0.2894\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9180 - val_loss: 0.2985\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9180 - val_loss: 0.3078\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9016 - val_loss: 0.2886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188280c3e00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1287e0cf-60eb-43a8-bb36-a4e9ef8cec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.9788 - loss: 0.1208\n",
      "Précision sur l'ensemble test : 0.98\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1960e9ad-6bcb-4802-9de9-23f2c918335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4dc3fa-ee74-4c00-899c-5d6fd9609844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 13  0]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.95      1.00      0.97        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.98        62\n",
      "   macro avg       0.98      0.99      0.99        62\n",
      "weighted avg       0.98      0.98      0.98        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f578e-8f3f-4503-9492-1a2047373a72",
   "metadata": {},
   "source": [
    "### ____________________________ MobileNetV2 ___________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77f4ae3-6eed-4ba4-a840-78253b7d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "MobileNetV2_model = MobileNetV2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "MobileNetV2_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7472e4bc-7836-4a4b-985b-08ab7b2d033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    MobileNetV2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d92f305f-0e6d-4f30-aef9-480baeb519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79e4b17-660d-40b6-a904-17d2ea611528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 930ms/step - accuracy: 0.6978 - loss: 0.5854 - val_accuracy: 0.8852 - val_loss: 0.2925\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 651ms/step - accuracy: 0.9858 - loss: 0.0621 - val_accuracy: 0.8689 - val_loss: 0.2711\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 571ms/step - accuracy: 0.9843 - loss: 0.0429 - val_accuracy: 0.9508 - val_loss: 0.1715\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 542ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9344 - val_loss: 0.1765\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9180 - val_loss: 0.1810\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 653ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9180 - val_loss: 0.1934\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9344 - val_loss: 0.1809\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9180 - val_loss: 0.1956\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9016 - val_loss: 0.2106\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 612ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9344 - val_loss: 0.1958\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 577ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9180 - val_loss: 0.2024\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9344 - val_loss: 0.1988\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 512ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9344 - val_loss: 0.1957\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 552ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1941\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 568ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9344 - val_loss: 0.1958\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9344 - val_loss: 0.1962\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9344 - val_loss: 0.2095\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 546ms/step - accuracy: 1.0000 - loss: 8.1141e-04 - val_accuracy: 0.9344 - val_loss: 0.2028\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 521ms/step - accuracy: 1.0000 - loss: 8.9021e-04 - val_accuracy: 0.9344 - val_loss: 0.2031\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 6.9993e-04 - val_accuracy: 0.9344 - val_loss: 0.2067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18877f45f10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6678ac69-a4fe-4046-9823-6d59b787f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.9150 - loss: 0.1649\n",
      "Précision sur l'ensemble test : 0.92\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d038f752-a0ad-44ea-841f-b7ed44696b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07147d48-9fb6-48f8-a984-c8eb410089ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[15  0  3]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.83      0.88        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.88      0.97      0.92        31\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.94      0.91      0.92        62\n",
      "weighted avg       0.92      0.92      0.92        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36ddde-3133-472f-a991-b981ab35d200",
   "metadata": {},
   "source": [
    "### ______________________________________________ DenceNet121 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c729e55-e2f3-4672-bae9-add740d2da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet121_model = DenseNet121(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet121_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet121_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8869314-233b-4bea-8b5a-4e7433378c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - accuracy: 0.6852 - loss: 0.6990 - val_accuracy: 0.9016 - val_loss: 0.3084\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.9359 - loss: 0.1688 - val_accuracy: 0.9672 - val_loss: 0.1935\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9856 - loss: 0.0815 - val_accuracy: 0.9180 - val_loss: 0.1801\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0394 - val_accuracy: 0.9836 - val_loss: 0.1290\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.9836 - val_loss: 0.1187\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.9836 - val_loss: 0.1188\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9836 - val_loss: 0.1110\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9836 - val_loss: 0.1067\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9836 - val_loss: 0.1046\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9836 - val_loss: 0.1019\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9836 - val_loss: 0.0990\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9836 - val_loss: 0.1015\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9836 - val_loss: 0.0953\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9836 - val_loss: 0.0940\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9836 - val_loss: 0.0924\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9836 - val_loss: 0.0918\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9836 - val_loss: 0.0905\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1771s\u001b[0m 80s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9836 - val_loss: 0.0946\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9836 - val_loss: 0.0894\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9836 - val_loss: 0.0923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188974b4a70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0ccacd-5153-427b-a008-b9478d751142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9785 - loss: 0.0427\n",
      "Précision sur l'ensemble test : 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a54955-38b1-45cb-867e-0ffc2acea6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001890A5C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 16s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001890A5C7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "253636f1-848a-4fb4-b6da-fc6ec01bced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[18  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      1.00      1.00        18\n",
      "    septoria       1.00      0.85      0.92        13\n",
      " stripe_rust       0.94      1.00      0.97        31\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.98      0.95      0.96        62\n",
      "weighted avg       0.97      0.97      0.97        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe90c0-9d55-4f8f-97f6-adc01db85389",
   "metadata": {},
   "source": [
    "### ________________________________________ DenseNet169 ___________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baef7a63-9540-4b39-83e8-77b7a9057ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "# Construction du modèle MobileNetV2\n",
    "DenseNet169_model = DenseNet169(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "DenseNet169_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    DenseNet169_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fc9f2d0-116a-4378-8699-e55f1f7b28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 5s/step - accuracy: 0.6506 - loss: 0.7964 - val_accuracy: 0.8197 - val_loss: 0.3906\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.9438 - loss: 0.1499 - val_accuracy: 0.9180 - val_loss: 0.2425\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.9848 - loss: 0.0623 - val_accuracy: 0.9180 - val_loss: 0.2384\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.9344 - val_loss: 0.1650\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.9180 - val_loss: 0.2333\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9344 - val_loss: 0.2150\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9344 - val_loss: 0.1831\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9344 - val_loss: 0.1687\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9344 - val_loss: 0.1835\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9344 - val_loss: 0.2067\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9344 - val_loss: 0.2086\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9344 - val_loss: 0.1961\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9344 - val_loss: 0.1948\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9344 - val_loss: 0.1810\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9344 - val_loss: 0.2073\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9344 - val_loss: 0.1971\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9344 - val_loss: 0.1919\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9344 - val_loss: 0.1795\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1872\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9344 - val_loss: 0.1897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x188974f4800>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c10ac2a-c892-440d-b246-7ee5ce93c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.1091\n",
      "Précision sur l'ensemble test : 0.97\n"
     ]
    }
   ],
   "source": [
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a61d315d-8200-4efd-b2d1-751f7ae830eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 22s/step\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d66f127b-18d7-4be6-965d-8f5042a07f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 13  0]\n",
      " [ 0  0 31]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      0.89      0.94        18\n",
      "    septoria       1.00      1.00      1.00        13\n",
      " stripe_rust       0.94      1.00      0.97        31\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.98      0.96      0.97        62\n",
      "weighted avg       0.97      0.97      0.97        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56ce50-1af4-4c9d-8c80-4fb6bc771195",
   "metadata": {},
   "source": [
    "### ____________________________________________ ResNet50V2 __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9da1f1e-3e44-45f4-92e9-b7b6f0f4bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "# Construction du modèle MobileNetV2\n",
    "ResNet50V2_model = ResNet50V2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "ResNet50V2_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    ResNet50V2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40150701-899c-440d-9fcc-3e2e6053cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.7191 - loss: 0.6685 - val_accuracy: 0.8361 - val_loss: 0.3646\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9814 - loss: 0.0634 - val_accuracy: 0.9016 - val_loss: 0.2464\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8689 - val_loss: 0.2832\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8852 - val_loss: 0.2701\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8689 - val_loss: 0.2872\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8852 - val_loss: 0.2797\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8852 - val_loss: 0.2820\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8852 - val_loss: 0.2764\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8852 - val_loss: 0.2997\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8852 - val_loss: 0.2832\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8852 - val_loss: 0.2925\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.2918\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8852 - val_loss: 0.2955\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8852 - val_loss: 0.2923\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.1562e-04 - val_accuracy: 0.8852 - val_loss: 0.2987\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.9567e-04 - val_accuracy: 0.8852 - val_loss: 0.3020\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.6005e-04 - val_accuracy: 0.8852 - val_loss: 0.3041\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.4164e-04 - val_accuracy: 0.8852 - val_loss: 0.3065\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 5.2828e-04 - val_accuracy: 0.8852 - val_loss: 0.3086\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.8260e-04 - val_accuracy: 0.8852 - val_loss: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1896d7d5610>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f98aef-d55f-4bf1-962a-24a67478df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9362 - loss: 0.0972\n",
      "Précision sur l'ensemble test : 0.94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "412b1c96-513f-408b-a06c-7ba4828ab85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f05093f5-6b86-4d1f-89b1-4187b95b8039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[16  0  2]\n",
      " [ 0 12  1]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.89      0.91        18\n",
      "    septoria       1.00      0.92      0.96        13\n",
      " stripe_rust       0.91      0.97      0.94        31\n",
      "\n",
      "    accuracy                           0.94        62\n",
      "   macro avg       0.95      0.93      0.94        62\n",
      "weighted avg       0.94      0.94      0.94        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883bd6a-b0c3-4234-a85d-f35ac6933e31",
   "metadata": {},
   "source": [
    "_________________________________________________________ ResNet152V2 ___________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cd6016-7027-455f-a02b-2795620c871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152V2\n",
    "# Construction du modèle MobileNetV2\n",
    "ResNet152V2_model = ResNet152V2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "ResNet152V2_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    ResNet152V2_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab826bc8-a7ae-4ecc-9d70-158a592c0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 7s/step - accuracy: 0.6585 - loss: 0.8428 - val_accuracy: 0.8361 - val_loss: 0.4298\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 6s/step - accuracy: 0.9794 - loss: 0.0764 - val_accuracy: 0.8852 - val_loss: 0.3257\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.8689 - val_loss: 0.2752\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.8852 - val_loss: 0.3194\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8852 - val_loss: 0.2819\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8852 - val_loss: 0.2859\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8852 - val_loss: 0.3162\n",
      "Epoch 8/20\n",
      "\u001b[1m 4/23\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_augmented_train, y_augmented_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_valid, y_valid))\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(X_augmented_train, y_augmented_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9046fdf-9ddd-4b14-8fa3-835de8609121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step - accuracy: 0.9462 - loss: 0.1401\n",
      "Précision sur l'ensemble test : 0.92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Évaluation sur l'ensemble test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble test : {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5fbd7e6-e16d-40ff-93f4-0e5438ad096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757ca407-6fa0-41cb-b61a-554a38c8cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[17  1  0]\n",
      " [ 0 10  3]\n",
      " [ 1  0 30]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      0.94      0.94        18\n",
      "    septoria       0.91      0.77      0.83        13\n",
      " stripe_rust       0.91      0.97      0.94        31\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.92      0.89      0.91        62\n",
      "weighted avg       0.92      0.92      0.92        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matrice de confusion et rapport de classification\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Rapport de classification :\")\n",
    "target_names = [str(cls) for cls in lb.classes_]\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824e57b-2152-4df5-a319-835b21076858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
