{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14b2adc-dd8f-4708-9ee4-9eebeabc691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf46f1f5-da1d-4f24-b312-f1184718427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_images_and_labels(dataset_path, img_size=(224, 224)):\n",
    "    images, labels = [], []\n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        for img_file in os.listdir(os.path.join(dataset_path, label_dir)):\n",
    "            img_path = os.path.join(dataset_path, label_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, img_size)\n",
    "            images.append(image)\n",
    "            labels.append(label_dir)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(\"./wheat_leaf\")\n",
    "images = images / 255.0  # Normalize the images to [0, 1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfd8a86-a401-4a89-8cc9-b5d6704c4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e495165-d7ec-4ae1-9400-223b6bd5cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d35f69d-992c-4a65-adf9-7415873cf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in the training set: Counter({2: 150, 1: 70, 0: 64})\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in the training set\n",
    "from collections import Counter\n",
    "class_distribution = Counter(np.argmax(y_train, axis=1))\n",
    "print(\"Class distribution in the training set:\", class_distribution)\n",
    "\n",
    "# Apply SMOTE for oversampling the minority class\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)  # Flatten images for SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_flattened, y_train)\n",
    "\n",
    "# Reshape back to image dimensions after SMOTE\n",
    "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1f832b-f2a8-49c5-b6a4-ad644301865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using MobileNetV2\n",
    "mobilenet = MobileNetV2(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "mobilenet.trainable = False  # Freeze the MobileNetV2 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d75d2a-037f-4261-86e3-85f88831d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    mobilenet,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),  # Dense layer for feature learning\n",
    "    layers.Dense(len(lb.classes_), activation='softmax')  # Output layer for classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b03ab03-4e3c-4b03-bc43-81d74a59f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ca3eca-9182-4cf2-a8d7-da89bc54e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 896ms/step - accuracy: 0.6560 - loss: 0.6962 - val_accuracy: 0.8689 - val_loss: 0.2972\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 536ms/step - accuracy: 0.9673 - loss: 0.1179 - val_accuracy: 0.9180 - val_loss: 0.2110\n",
      "Epoch 3/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 504ms/step - accuracy: 0.9866 - loss: 0.0543 - val_accuracy: 0.9180 - val_loss: 0.1905\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 511ms/step - accuracy: 0.9984 - loss: 0.0301 - val_accuracy: 0.9016 - val_loss: 0.2096\n",
      "Epoch 5/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.9180 - val_loss: 0.1934\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 522ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9672 - val_loss: 0.1497\n",
      "Epoch 7/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 513ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9180 - val_loss: 0.2006\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 507ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9180 - val_loss: 0.1809\n",
      "Epoch 9/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9180 - val_loss: 0.1732\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9180 - val_loss: 0.1881\n",
      "Epoch 11/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 511ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9180 - val_loss: 0.1716\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9180 - val_loss: 0.1739\n",
      "Epoch 13/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9180 - val_loss: 0.1731\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 552ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9180 - val_loss: 0.1800\n",
      "Epoch 15/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 533ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9180 - val_loss: 0.1824\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9344 - val_loss: 0.1740\n",
      "Epoch 17/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9180 - val_loss: 0.1769\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9344 - val_loss: 0.1734\n",
      "Epoch 19/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9344 - val_loss: 0.1724\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 549ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9344 - val_loss: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22526c47e00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_resampled, y_resampled, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af094f3-d7cc-4ba8-aeab-20e3753bb485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.9150 - loss: 0.1607\n",
      "Test accuracy: 0.9193548560142517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c51371-6c9a-4f19-8635-0f6fbb0b0426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
